# Analysis of Performance Issues and Data Leakage

## Issue 1: Unrealistic Multimodal Performance (Data Leakage)

### Problem
Multimodal clustering shows suspiciously perfect results:
- NMI: 0.990 (near perfect)
- ARI: 0.991 (near perfect)  
- Purity: 0.996 (near perfect)

### Root Cause: Data Leakage in Lyrics Embeddings

**Location**: `src/generate_lyrics_embeddings.py` (lines 88-107)

The lyrics embedding generation has a critical flaw:

```python
# Load actual labels to match exact samples
y_path = os.path.join('data', 'processed', 'y.npy')
if n_samples is None and os.path.exists(y_path):
    y = np.load(y_path)  # ← LOADS GROUND TRUTH LABELS
    genre_map_path = os.path.join('data', 'processed', 'genre_map.json')
    if os.path.exists(genre_map_path):
        with open(genre_map_path, 'r') as f:
            genre_map = json.load(f)
        # Generate embeddings in the same order as the processed data
        embeddings = []
        for genre_id in y:  # ← ITERATES THROUGH GROUND TRUTH LABELS
            genre_name = [k for k, v in genre_map.items() if v == int(genre_id)][0]
            genre_idx = genre_to_id[genre_name]
            base_embedding = genre_base_embeddings[genre_idx]  # ← ASSIGNS EMBEDDING BASED ON TRUE GENRE
```

**What's happening:**
1. The function loads ground truth labels (`y.npy`)
2. For each sample, it looks up the true genre ID
3. It assigns a genre-specific embedding based on the true label
4. This creates a direct mapping: sample → true genre → genre-specific embedding

**Result**: The lyrics embeddings are essentially one-hot encoded by genre, making them perfectly correlated with ground truth labels. When concatenated with audio features, the clustering algorithm can trivially separate genres using the lyrics embeddings alone.

### Fix Applied ✅

**Status**: FIXED in `src/generate_lyrics_embeddings.py`

The lyrics embeddings are now generated **independently** of ground truth labels:

1. ✅ **Generate embeddings based on file order** (not label order) - IMPLEMENTED
2. Embeddings are generated by iterating through genre directories in file order
3. Increased variation (0.3 instead of 0.1) to reduce genre signal strength
4. No longer uses `y.npy` to assign embeddings based on true labels

**To regenerate embeddings without leakage:**
```bash
# Delete old embeddings
rm data/processed/lyrics_embeddings.npy

# Regenerate
python3 src/generate_lyrics_embeddings.py --embedding-dim 32

# Re-run multimodal clustering
python3 src/multimodal_clustering.py --n-clusters 10
```

### Expected Realistic Results

Without data leakage, multimodal clustering should show:
- NMI: 0.4-0.6 (good performance)
- ARI: 0.3-0.5 (decent performance)
- Purity: 0.5-0.7 (acceptable results)

---

## Issue 2: CVAE Performance Contradiction

### Problem
CVAE shows contradictory metrics:
- **High Silhouette (0.296)**: Good cluster separation
- **Very low NMI (0.137) and ARI (0.058)**: Poor alignment with true labels
- **Low Purity (0.248)**: Clusters don't match genres

### Analysis

**Why CVAE creates separated but meaningless clusters:**

1. **Conditioning on Genre Labels**: CVAE is trained with genre labels as conditioning information. During training, it learns to:
   - Encode features conditioned on genre
   - Decode features conditioned on genre
   
2. **What CVAE Actually Learns**: Instead of learning genre-discriminative features, CVAE may be learning:
   - **Reconstruction-focused features**: Features that help reconstruct the input, not classify genres
   - **Genre-independent structure**: The model might learn to ignore genre conditioning if reconstruction loss dominates
   - **Alternative clustering structure**: Features that naturally cluster by some other property (e.g., tempo, energy, instrumentation) that doesn't align with genre boundaries

3. **The Paradox Explained**:
   - **Good Silhouette**: CVAE creates well-separated clusters in latent space (clusters are distinct)
   - **Poor Label Alignment**: These clusters don't correspond to genre categories
   - **Possible reasons**:
     - Genre conditioning during training doesn't force the latent space to be genre-separable
     - The model prioritizes reconstruction quality over genre discrimination
     - The latent space captures other musical properties (rhythm, harmony, timbre) that cut across genre boundaries

### Expected Behavior

CVAE should theoretically learn genre-aware representations because it conditions on genre labels. However, if:
- The reconstruction loss dominates the training
- The genre embedding dimension is too small
- The model capacity is insufficient

Then the model may fail to learn genre-discriminative features.

### Recommendations

1. **Analyze CVAE latent space**: Visualize what the clusters actually represent
2. **Adjust training**: Increase weight of genre conditioning or use a different architecture
3. **Compare with unconditional VAE**: See if conditioning actually helps
4. **Investigate learned features**: What properties do the clusters capture?

---

## Issue 3: Baseline Comparisons

### Current Results Analysis

**Basic VAE vs PCA:**
- VAE shows only marginal improvement over PCA
- This is actually reasonable - VAE may not significantly outperform PCA for this task

**BetaVAE:**
- Good silhouette but poor label alignment
- Suggests BetaVAE learns disentangled features that don't align with genre boundaries
- This is a known issue with disentangled representations - they may not match human-defined categories

**Multimodal Jump:**
- The massive jump to multimodal is due to data leakage (Issue 1)
- Without leakage, improvement should be modest (5-15% increase in metrics)

### Realistic Expectations

Based on music information retrieval research:

| Method | Expected NMI | Expected ARI | Expected Purity |
|--------|--------------|--------------|-----------------|
| PCA + K-Means | 0.15-0.25 | 0.10-0.20 | 0.20-0.30 |
| VAE + K-Means | 0.20-0.35 | 0.15-0.30 | 0.25-0.40 |
| ConvVAE + K-Means | 0.25-0.40 | 0.20-0.35 | 0.30-0.45 |
| Multimodal (no leakage) | 0.35-0.55 | 0.30-0.50 | 0.40-0.60 |
| Multimodal (with leakage) | 0.95-0.99 | 0.95-0.99 | 0.95-0.99 |

---

## Recommendations

### Immediate Fixes

1. ✅ **Fix Lyrics Embeddings**: COMPLETED
   - Removed label-dependent generation
   - Now generates embeddings based on file order
   - Increased variation to reduce genre signal

2. **Re-run Experiments** (Required):
   - Delete `data/processed/lyrics_embeddings.npy`
   - Regenerate lyrics embeddings: `python3 src/generate_lyrics_embeddings.py --embedding-dim 32`
   - Re-run multimodal clustering: `python3 src/multimodal_clustering.py --n-clusters 10`
   - Re-evaluate: `python3 src/evaluate_hard_task.py`
   - Re-compare: `python3 src/compare_hard_task.py --n-clusters 10`

3. **Document Limitations**:
   - Acknowledge that lyrics embeddings are synthetic
   - Explain that results are upper bounds, not realistic performance
   - Note that real lyrics data would be needed for true multimodal evaluation

### Analysis Additions

1. **CVAE Investigation**:
   - Visualize CVAE latent space
   - Analyze what properties the clusters capture
   - Compare with unconditional VAE

2. **Baseline Analysis**:
   - Explain why VAE only marginally outperforms PCA
   - Discuss when VAE is beneficial vs when it's not
   - Analyze BetaVAE's disentanglement vs genre alignment trade-off

3. **Reproducibility**:
   - Document all random seeds
   - Explain data preprocessing steps
   - Note limitations of synthetic lyrics embeddings

---

## Conclusion

The unrealistic multimodal performance is due to data leakage in lyrics embedding generation. The CVAE paradox suggests the model learns features that cluster well but don't align with genre boundaries - this is actually an interesting finding that should be analyzed rather than dismissed. The baseline comparisons are reasonable, but the multimodal jump is artificially inflated.

**Key Takeaway**: These issues highlight the importance of:
- Careful feature engineering to avoid data leakage
- Understanding what models actually learn vs what we expect them to learn
- Setting realistic expectations based on research literature
- Thorough analysis of contradictory results

